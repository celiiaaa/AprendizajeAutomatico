{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "**Qué vamos a ver:**\n",
    "- Ajuste de hiperparámetros en los árboles de decisión\n",
    "- Combinar el ajuste de hiperparámetros y la evaluación de modelos\n",
    "    - GridSearch\n",
    "    - RandomSearch\n",
    "    - Optimización basada en modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros de los árboles de decisión. Ajuste de los árboles de decisión.\n",
    "---\n",
    "- *max_depth : int or None, opcional (por defecto=None)*\n",
    "\n",
    "    La profundidad máxima del árbol. Si es None, los nodos se expanden hasta que todas las hojas sean puras o hasta que todas las hojas contengan menos muestras que min_samples_split. Se ignora si max_leaf_nodes no es None.\n",
    "    \n",
    "- *min_samples_split : int, opcional (por defecto=2)*\n",
    "\n",
    "    El número mínimo de muestras necesarias para dividir un nodo interno.\n",
    "\n",
    "- Hay más parámetros:\n",
    "  - https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "  - https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargan los datos, las entradas van a X, las salidas a y.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from scipy.stats import sem\n",
    "\n",
    "housing_meta = fetch_california_housing()\n",
    "X = housing_meta.data\n",
    "y = housing_meta.target\n",
    "\n",
    "print(housing_meta.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinación entre el ajuste de hiperparámetros y la evaluación del modelo.\n",
    "---\n",
    "La combinación de evaluación de modelos y ajuste de hiperparámetros puede entenderse como un bucle externo (*outer*) que entrena un modelo y prueba el modelo, y un bucle interno (*inner*), donde el proceso de entrenamiento consiste en buscar los mejores hiperparámetros, y luego obtener el modelo con esos mejores hiperparámetros.\n",
    "\n",
    "- En primer lugar, vamos a utilizar **Holdout** (entrenar/probar) para la evaluación del modelo (bucle externo o *outer*)\n",
    "- **3-fold crossvalidation** para el ajuste de los hiperparámetros (bucle interno o *inner*)\n",
    "- Los hiperparámetros se ajustarán con **Gridsearch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>1. GRIDSEARCH.</u>\n",
    "\n",
    "Tabla en la que se prueba todo con todo --> busqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Función RMSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias.\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# Definamos nuestra función python para el RMSE.\n",
    "def rmse(y_test, y_test_pred):\n",
    "  \"\"\" This is my computation of Root Mean Squared Error \"\"\"\n",
    "  return np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la función train_test_split de sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Holdout para el modelo de evaluación. 33% of available data for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSE con hiperparámetros por defecto**\n",
    "\n",
    "En primer lugar, recordemos el RMSE con hiperparámetros por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of tree with default hyper-pars: 0.7389833060012664\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regr = DecisionTreeRegressor()\n",
    "np.random.seed(42)\n",
    "regr.fit(X=X_train, y=y_train)\n",
    "print(f\"RMSE of tree with default hyper-pars: {rmse(y_test, regr.predict(X=X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=DecisionTreeRegressor(), n_jobs=1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 4, 6, 8, 10, 12, 14],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 4, 6, 8, 10, 12, 14]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=DecisionTreeRegressor(), n_jobs=1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 4, 6, 8, 10, 12, 14],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 4, 6, 8, 10, 12, 14]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=DecisionTreeRegressor(), n_jobs=1,\n",
       "             param_grid={'max_depth': [2, 4, 6, 8, 10, 12, 14],\n",
       "                         'min_samples_split': [2, 4, 6, 8, 10, 12, 14]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# Search space\n",
    "param_grid = {'max_depth': list(range(2,16,2)),\n",
    "              'min_samples_split': list(range(2,16,2))}\n",
    "\n",
    "inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Definition of a 2-step process that self-adjusts 2 hyperpars\n",
    "regr = GridSearchCV(DecisionTreeRegressor(),\n",
    "                   param_grid,\n",
    "                   scoring='neg_mean_squared_error',\n",
    "                   cv=inner,\n",
    "                   n_jobs=1, verbose=1)\n",
    "\n",
    "# Train the self-adjusting process\n",
    "np.random.seed(42)\n",
    "regr.fit(X=X_train, y=y_train)\n",
    "\n",
    "# At this point, regr contains the model with the best hyper-parameters found by gridsearch\n",
    "# and trained on the complete X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of tree with hyper-parameter tuning (grid-search): 0.6647688056188821\n"
     ]
    }
   ],
   "source": [
    "# Now, the performance of regr is computed on the test partition\n",
    "print(f\"RMSE of tree with hyper-parameter tuning (grid-search): {rmse(y_test, regr.predict(X=X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 8, 'min_samples_split': 14}, 0.44782374157784616)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veamos los mejores hiperparámetros y su puntuación (MSE). \n",
    "# Podemos ver que están cerca de los extremos del espacio de parámetros, pero no en el extremo.\n",
    "regr.best_params_, -regr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>2. Búsqueda aleatoria </u>(*RANDOMIZED SEARCH*)\n",
    "\n",
    "Ahora, utilicemos *Randomized Search* en lugar de *GridSearch*. \n",
    "\n",
    "No es la mejor solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-KFold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=DecisionTreeRegressor(), n_iter=20, n_jobs=1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [2, 4, 6, 8, 10, 12, 14],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 4, 6, 8, 10,\n",
       "                                                              12, 14]},\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=DecisionTreeRegressor(), n_iter=20, n_jobs=1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [2, 4, 6, 8, 10, 12, 14],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 4, 6, 8, 10,\n",
       "                                                              12, 14]},\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=DecisionTreeRegressor(), n_iter=20, n_jobs=1,\n",
       "                   param_distributions={'max_depth': [2, 4, 6, 8, 10, 12, 14],\n",
       "                                        'min_samples_split': [2, 4, 6, 8, 10,\n",
       "                                                              12, 14]},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sólo se probarán 20 combinaciones de valores de hiperparámetros (budget=20)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# Search space\n",
    "param_grid = {'max_depth': list(range(2,16,2)),\n",
    "              'min_samples_split': list(range(2,16,2))}\n",
    "\n",
    "# Inner evaluation\n",
    "inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Cambia esto: ahora busca en budget 20 y en random\n",
    "budget = 20\n",
    "regr = RandomizedSearchCV(DecisionTreeRegressor(),\n",
    "                         param_grid,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         cv=inner,\n",
    "                         n_jobs=1, verbose=1,\n",
    "                         n_iter=budget\n",
    "                        )\n",
    "np.random.seed(42)\n",
    "regr.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of tree with hyper-parameter tuning (random search): 0.6640044054767447\n"
     ]
    }
   ],
   "source": [
    "# Now, the performance of regr is computed on the test partition\n",
    "print(f\"RMSE of tree with hyper-parameter tuning (random search): {rmse(y_test, regr.predict(X=X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados**\n",
    "\n",
    "El valor de error empeora.\n",
    "\n",
    "Posibles mejores soluciones:\n",
    "- Busqueda bayesiana\n",
    "- Buqueda algoritmo genético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'min_samples_split': 12, 'max_depth': 8}, 0.4452664287620658)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.best_params_, -regr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unifor y expon**\n",
    "\n",
    "Para la **Búsqueda Aleatoria**, podemos definir el espacio de búsqueda con distribuciones estadísticas, en lugar de utilizar valores particulares como hacíamos antes. A continuación puedes ver cómo utilizar una distribución uniforme sobre enteros entre 2 y 16 mediante *randint*. Para hiperparámetros continuos podríamos usar distribuciones continuas como *uniform* o *expon* (exponencial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=DecisionTreeRegressor(), n_iter=20, n_jobs=1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x17d1b3220&gt;,\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x17d19ef70&gt;},\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=DecisionTreeRegressor(), n_iter=20, n_jobs=1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x17d1b3220&gt;,\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x17d19ef70&gt;},\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                   estimator=DecisionTreeRegressor(), n_iter=20, n_jobs=1,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x17d1b3220>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x17d19ef70>},\n",
       "                   scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn import metrics\n",
    "from scipy.stats import uniform, expon\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "# Search space with integer uniform distributions\n",
    "param_grid = {'max_depth': sp_randint(2,16),\n",
    "              'min_samples_split': sp_randint(2,16)}\n",
    "\n",
    "inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "budget = 20\n",
    "regr = RandomizedSearchCV(DecisionTreeRegressor(),\n",
    "                         param_grid,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         cv=inner,\n",
    "                         n_jobs=1, verbose=1,\n",
    "                         n_iter=budget\n",
    "                        )\n",
    "\n",
    "np.random.seed(42)\n",
    "regr.fit(X=X_train, y=y_train)\n",
    "\n",
    "# At this point, regr contains the model with the best hyper-parameters found by gridsearch\n",
    "# and trained on the complete X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of tree with hyper-parameter tuning (random search II): 0.6640044054767447\n"
     ]
    }
   ],
   "source": [
    "# Now, the performance of regr is computed on the test partition\n",
    "print(f\"RMSE of tree with hyper-parameter tuning (random search II): {rmse(y_test, regr.predict(X=X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 8, 'min_samples_split': 12}, 0.4483635388476918)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.best_params_, -regr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5-KFold**\n",
    "\n",
    "¿Y si quisiéramos hacer **evaluación de modelos con 5-fold crossvalidation** y **ajuste de hiperparámetros con 3-fold crossvalidation**? Esto se denomina validación cruzada anidada (https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html). Hay un bucle externo (para evaluar los modelos) y un bucle interno (para ajustar los hiperparámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# random_state=42 for reproducibility\n",
    "# Evaluation of model (outer loop)\n",
    "outer = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "from scipy.stats import uniform, expon\n",
    "\n",
    "# Search space\n",
    "param_grid = {'max_depth': list(range(2,16,2)),\n",
    "              'min_samples_split': list(range(2,16,2))}\n",
    "\n",
    "inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "budget = 20\n",
    "# This is the internal 3-fold crossvalidation for hyper-parameter tuning\n",
    "regr = RandomizedSearchCV(DecisionTreeRegressor(),\n",
    "                         param_grid,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         # 3-fold for hyper-parameter tuning\n",
    "                         cv=inner,\n",
    "                         n_jobs=1, verbose=1,\n",
    "                         n_iter=budget\n",
    "                        )\n",
    "\n",
    "# This is the external 5-fold crossvalidation for model evaluation\n",
    "# Notice that regr is the model resulting of hyper-parameter tuning\n",
    "np.random.seed(42)\n",
    "\n",
    "# For sklearn, higher scores are better. Given that MSE is an error (smaller is better), the corresponding score is -MSE\n",
    "scores = -cross_val_score(regr,\n",
    "                            X, y,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            cv = outer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42013123 0.40583334 0.39388899 0.4006011  0.41832784]\n",
      "0.6385089628008911 +- 0.00792487477201872\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "# The score was MSE, we want RMSE\n",
    "scores = np.sqrt(scores)\n",
    "# The mean of the 5-fold crossvalidation is the final score of the model\n",
    "print(f\"{scores.mean()} +- {scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo final**\n",
    "\n",
    "Obtención del modelo final (para su despliegue, o para enviarlo a un concurso, ...)\n",
    "\n",
    "Si necesitamos un modelo final, podemos obtenerlo ajustando regr a todos los datos disponibles. Recordemos que regr hace ajuste de hiper-parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Fitting again the randomized search HPO\n",
    "regrFinal = regr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'min_samples_split': 14, 'max_depth': 10}, 0.3993552378121243)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.best_params_, -regr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>3. Optimización basada en modelos.</u> (*BAYESIAN OPTIMIZATION*)\n",
    "\n",
    "Para ello se utilizará scikit-optimize (skopt): https://scikit-optimize.github.io. **Holdout** para la evaluación del modelo y **3-fold crossvalidation** para el ajuste de hiperparámetros (con **Model Based Optimization** )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.0\n",
      "1.3.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install scikit-learn==0.24.2\n",
    "#!pip install scikit-optimize\n",
    "#!pip install git+https://github.com/scikit-optimize/scikit-optimize.git\n",
    "\n",
    "# Checking that everything is correct with skopt (0.9.dev0) and sklearn\n",
    "\n",
    "from skopt import __version__\n",
    "print(__version__)\n",
    "from sklearn import __version__\n",
    "print(__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Cambiamos otra vez el budget y el tipo de busqueda\u001b[39;00m\n\u001b[1;32m     14\u001b[0m budget \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m---> 15\u001b[0m regr \u001b[38;5;241m=\u001b[39m BayesSearchCV(\u001b[43mDecisionTreeRegressor\u001b[49m(),\n\u001b[1;32m     16\u001b[0m                     param_grid,\n\u001b[1;32m     17\u001b[0m                     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m                     cv\u001b[38;5;241m=\u001b[39minner,\n\u001b[1;32m     19\u001b[0m                     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     20\u001b[0m                     n_iter\u001b[38;5;241m=\u001b[39mbudget\n\u001b[1;32m     21\u001b[0m                     )\n\u001b[1;32m     22\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     23\u001b[0m regr\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX_train, y\u001b[38;5;241m=\u001b[39my_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from sklearn import metrics\n",
    "from skopt.plots import plot_objective, plot_histogram, plot_convergence\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Search space with integer uniform distributions\n",
    "param_grid = {'max_depth': Integer(2,20),\n",
    "              'min_samples_split': Integer(20,100)}\n",
    "\n",
    "inner = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Cambiamos otra vez el budget y el tipo de busqueda\n",
    "budget = 20\n",
    "regr = BayesSearchCV(DecisionTreeRegressor(),\n",
    "                    param_grid,\n",
    "                    scoring='neg_mean_squared_error',\n",
    "                    cv=inner,\n",
    "                    n_jobs=1, verbose=1,\n",
    "                    n_iter=budget\n",
    "                    )\n",
    "np.random.seed(42)\n",
    "regr.fit(X=X_train, y=y_train)\n",
    "\n",
    "# At this point, regr contains the model with the best hyper-parameters found by bayessearch\n",
    "# and trained on the complete X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BayesSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Now, the performance of regr is computed on the test partition\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE of tree with hyper-parameter tuning (bayesian optimization): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse(y_test,\u001b[38;5;250m \u001b[39mregr\u001b[38;5;241m.\u001b[39mpredict(X\u001b[38;5;241m=\u001b[39mX_test))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:519\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \n\u001b[1;32m    503\u001b[0m \u001b[38;5;124;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;124;03m    the best found parameters.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    518\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BayesSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "# Now, the performance of regr is computed on the test partition\n",
    "print(f\"RMSE of tree with hyper-parameter tuning (bayesian optimization): {rmse(y_test, regr.predict(X=X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BayesSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mregr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_params_\u001b[49m, \u001b[38;5;241m-\u001b[39mregr\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BayesSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "regr.best_params_, -regr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot de convergencia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos comprobar si la optimización ha convergido\n",
    "_ = plot_convergence(regr.optimizer_results_[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deberíamos de llegar a parar en una recta.\n",
    "_ = plot_objective(regr.optimizer_results_[0],\n",
    "                   dimensions=['max_depth', 'min_samples_split'],\n",
    "                   n_minimum_search=int(1e8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante**\n",
    "\n",
    "El número de ejemplos mínimo --> 48.\n",
    "\n",
    "Para la práctica: random y si queremos el bayesiana (pros)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
